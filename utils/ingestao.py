"""
ingestao.py ‚Äî Script de ingest√£o de documentos para o CALIA V2.0

Este m√≥dulo realiza:
 - Leitura autom√°tica de arquivos (PDF, TXT e DOCX) da pasta /uploads/
 - Divis√£o do texto em partes (chunks)
 - Cria√ß√£o de embeddings com HuggingFace
 - Gera√ß√£o e salvamento do √≠ndice vetorial FAISS

Resultado:
Cria (ou atualiza) a pasta /faiss_index/ com o √≠ndice usado pelo RAG da CALIA.

Autor: Carlos
Projeto: CALIA V2.0
"""

import os
import logging
from pathlib import Path
from typing import List

# Bibliotecas LangChain
from langchain_community.document_loaders import PyMuPDFLoader, TextLoader, UnstructuredWordDocumentLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO, format="[%(asctime)s] %(levelname)s: %(message)s")

# ============================
# ‚öôÔ∏è CONFIGURA√á√ïES DO SCRIPT
# ============================

UPLOADS_DIR = Path("uploads")
INDEX_DIR = Path("faiss_index")

# Modelo de embeddings (r√°pido e leve)
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

# Tamanho dos peda√ßos de texto
CHUNK_SIZE = 800
CHUNK_OVERLAP = 150


# ============================
# üß© FUN√á√ïES DE SUPORTE
# ============================

def carregar_arquivos() -> List:
    """
    Carrega todos os arquivos suportados da pasta /uploads/
    e retorna uma lista de Documentos LangChain.
    """
    documentos = []

    if not UPLOADS_DIR.exists():
        logging.warning(f"Pasta '{UPLOADS_DIR}' n√£o encontrada. Criando automaticamente...")
        UPLOADS_DIR.mkdir(parents=True, exist_ok=True)
        logging.info("Adicione arquivos PDF, TXT ou DOCX em '/uploads/' e execute novamente.")
        return []

    arquivos = [f for f in UPLOADS_DIR.iterdir() if f.suffix.lower() in [".pdf", ".txt", ".docx"]]

    if not arquivos:
        logging.warning("Nenhum arquivo encontrado em /uploads/.")
        return []

    for arquivo in arquivos:
        try:
            logging.info(f"Lendo arquivo: {arquivo.name}")

            if arquivo.suffix.lower() == ".pdf":
                loader = PyMuPDFLoader(str(arquivo))
            elif arquivo.suffix.lower() == ".txt":
                loader = TextLoader(str(arquivo), encoding="utf-8")
            elif arquivo.suffix.lower() == ".docx":
                loader = UnstructuredWordDocumentLoader(str(arquivo))
            else:
                logging.warning(f"Formato n√£o suportado: {arquivo.suffix}")
                continue

            documentos.extend(loader.load())
        except Exception as e:
            logging.error(f"Erro ao carregar {arquivo.name}: {e}")

    return documentos


def dividir_documentos(documentos: List) -> List:
    """
    Divide os documentos em peda√ßos menores (chunks)
    para melhor processamento e busca sem√¢ntica.
    """
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP
    )
    texts = splitter.split_documents(documentos)
    logging.info(f"Divididos {len(documentos)} documentos em {len(texts)} partes menores.")
    return texts


def criar_faiss_index(textos: List):
    """
    Cria o √≠ndice FAISS local com embeddings dos textos divididos.
    """
    logging.info("Gerando embeddings e criando √≠ndice FAISS...")

    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
    index = FAISS.from_documents(textos, embeddings)

    INDEX_DIR.mkdir(exist_ok=True)
    index.save_local(str(INDEX_DIR))

    logging.info(f"‚úÖ √çndice FAISS salvo em: {INDEX_DIR.resolve()}")


# ============================
# üöÄ EXECU√á√ÉO PRINCIPAL
# ============================

def main():
    """
    Fun√ß√£o principal de ingest√£o.
    Executa o pipeline completo de leitura, chunking e indexa√ß√£o.
    """
    logging.info("üöÄ Iniciando ingest√£o de documentos para o CALIA V2.0...")

    # 1Ô∏è‚É£ Carregar arquivos
    docs = carregar_arquivos()
    if not docs:
        logging.info("Nenhum documento processado. Encerrando ingest√£o.")
        return

    # 2Ô∏è‚É£ Dividir em partes menores
    textos = dividir_documentos(docs)

    # 3Ô∏è‚É£ Criar e salvar o √≠ndice FAISS
    criar_faiss_index(textos)

    logging.info("üéâ Ingest√£o conclu√≠da com sucesso! O CALIA agora pode responder com base nos seus arquivos.")


if __name__ == "__main__":
    main()
